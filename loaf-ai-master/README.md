![loaf-ai-gif](https://raw.githubusercontent.com/lawreka/loaf-ai/master/loafai.gif)

# loaf-ai

loaf-ai was built for the BitRate: Machine Learning & Music hackathon sponsored by [Gray Area](https://grayarea.org/) and Google [Magenta](https://magenta.tensorflow.org/).

loaf-ai allows the listener to assemble a lo fi hip hop track using piano, drum, and sound effect loops. While the tracks are loaded into [Tone.js](https://github.com/Tonejs/Tone.js), Magenta's Music RNN generates 40 samples of acoustic guitar improvisations to play over the selected chord progressions.

The resulting composition is a 15-minute-long jam to study / work / relax / to that is complex enough to be musically interesting, but not so unpredictable as to be a distraction. To add some visual interest and draw the listener's attention to the AI soloist's contributions, the guitar track is highlighted as a waveform at the bottom of the playing browser, adapted from Jason Sigal's [p5-music-viz](https://github.com/therewasaguy/p5-music-viz).

Read more -> [https://kathrynisabelle.com/loaf-ai-writeup](https://kathrynisabelle.com/loaf-ai-writeup)

Play -> [https://kathrynisabelle.com/loaf-ai](https://kathrynisabelle.com/loaf-ai)
(probably only works in Chrome, sorry)
